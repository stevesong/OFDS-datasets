name: Generate and Upload PMTiles to S3

on:
  push:
    branches: [main]
    paths:
      - '**/*.json'
      - '**/*.geojson'
  workflow_dispatch: # Allows manual triggering

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Install Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libsqlite3-dev zlib1g-dev jq
          git clone https://github.com/felt/tippecanoe.git
          cd tippecanoe
          make -j
          sudo make install
      
      - name: Generate Layered PMTiles
        run: |
          # Create a temporary directory for converted GeoJSON files
          mkdir -p temp_geojson
          layerArgs=""
          
          # Process each country/operator combination as a separate layer
          for country in $(find . -mindepth 1 -maxdepth 1 -type d -not -path "*/\.*" -not -path "*/temp_geojson" | sort); do
            countryName=$(basename $country)
            for operator in $(find $country -mindepth 1 -maxdepth 1 -type d | sort); do
              operatorName=$(basename $operator)
              
              # Create layer name
              layerName="${countryName}_${operatorName}"
              
              # Find JSON file
              ofdsFile=$(find $operator -name "*.json" | grep -v "package.json" | head -n 1)
              
              if [ -n "$ofdsFile" ]; then
                tempGeoJson="temp_geojson/${layerName}.geojson"
                
                echo "Converting $ofdsFile for $layerName"
                
                # Convert the JSON format with 'networks' array to GeoJSON
                jq '{
                  type: "FeatureCollection",
                  features: [
                    # Convert nodes to GeoJSON features
                    (.networks[].nodes[]? | {
                      type: "Feature",
                      id: .id,
                      geometry: .location,
                      properties: (. + {feature_type: "node"}) | del(.location)
                    }),
                    # Convert links to GeoJSON features
                    (.networks[].links[]? | {
                      type: "Feature",
                      id: .id,
                      geometry: .geometry,
                      properties: (. + {feature_type: "link"}) | del(.geometry)
                    })
                  ]
                }' "$ofdsFile" > "$tempGeoJson"
                
                # Check if file has features
                if [ -s "$tempGeoJson" ]; then
                  layerArgs="$layerArgs -L${layerName}:${tempGeoJson}"
                  echo "Added layer $layerName"
                fi
              fi
            done
          done
          
          # Create PMTiles if we have layers
          if [ -n "$layerArgs" ]; then
            echo "Creating PMTiles with layers: $layerArgs"
            tippecanoe -o ofds_networks_by_layer.pmtiles -zg --drop-densest-as-needed $layerArgs
          else
            echo "No valid layers found"
            exit 1
          fi
          
          # Clean up
          rm -rf temp_geojson
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Upload PMTiles to S3
        run: |
          # Upload the PMTiles file to S3
          aws s3 cp ofds_networks_by_layer.pmtiles s3://${{ secrets.S3_BUCKET_NAME }}/ofds_networks_by_layer.pmtiles --content-type 'application/octet-stream' --cache-control 'max-age=86400'
          
          # Create and upload metadata
          TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          cat > pmtiles_metadata.json << EOL
          {
            "updated_at": "${TIMESTAMP}",
            "files": {
              "layered": "https://${{ secrets.S3_BUCKET_NAME }}.s3.${{ secrets.AWS_REGION }}.amazonaws.com/ofds_networks_by_layer.pmtiles"
            }
          }
          EOL
          
          aws s3 cp pmtiles_metadata.json s3://${{ secrets.S3_BUCKET_NAME }}/pmtiles_metadata.json --content-type 'application/json' --cache-control 'max-age=300'