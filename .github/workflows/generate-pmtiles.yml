name: Generate and Upload PMTiles to S3

on:
  push:
    branches: [main]
    paths:
      - '**/*.geojson'
  workflow_dispatch: # Allows manual triggering

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Install Tippecanoe
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libsqlite3-dev zlib1g-dev
          git clone https://github.com/felt/tippecanoe.git
          cd tippecanoe
          make -j
          sudo make install
      
      - name: Generate One Layer Per Operator
        run: |
          # Create a file to store layer definitions
          echo "# Layer definitions for tippecanoe" > layers.txt
          
          # Process each country/operator combination
          for country in $(find . -mindepth 1 -maxdepth 1 -type d -not -path "*/\.*" -not -path "*/tippecanoe" | sort); do
            countryName=$(basename "$country")
            
            for operator in $(find "$country" -mindepth 1 -maxdepth 1 -type d | sort); do
              operatorName=$(basename "$operator")
              layerName="${countryName}_${operatorName}"
              
              # Find all GeoJSON files for this operator
              geojsonFiles=$(find "$operator" -name "*.geojson" | tr '\n' ' ')
              
              if [ -n "$geojsonFiles" ]; then
                echo "Found operator: $layerName with files: $geojsonFiles"
                echo "-L$layerName:$geojsonFiles" >> layers.txt
              fi
            done
          done
          
          # Count layers
          layerCount=$(grep -c "^-L" layers.txt || true)
          echo "Found $layerCount operator layers"
          
          # Run tippecanoe if we have any layers
          if [ "$layerCount" -gt 0 ]; then
            echo "Creating PMTiles using layer definitions from layers.txt"
            tippecanoe -o ofds_networks_by_layer.pmtiles -zg --drop-densest-as-needed $(cat layers.txt)
          else
            echo "No GeoJSON files found"
            exit 1
          fi
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Upload PMTiles to S3
        run: |
          # Upload the PMTiles file to S3
          aws s3 cp ofds_networks_by_layer.pmtiles s3://${{ secrets.S3_BUCKET_NAME }}/ofds_networks_by_layer.pmtiles --content-type 'application/octet-stream' --cache-control 'max-age=86400'
          
          # Upload the layer definitions file for reference
          aws s3 cp layers.txt s3://${{ secrets.S3_BUCKET_NAME }}/ofds_layers.txt --content-type 'text/plain' --cache-control 'max-age=86400'
          
          # Create metadata JSON
          cat > pmtiles_metadata.json << EOF
          {
            "updated_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "layer_count": $layerCount,
            "files": {
              "layered": "https://${{ secrets.S3_BUCKET_NAME }}.s3.${{ secrets.AWS_REGION }}.amazonaws.com/ofds_networks_by_layer.pmtiles",
              "layer_definitions": "https://${{ secrets.S3_BUCKET_NAME }}.s3.${{ secrets.AWS_REGION }}.amazonaws.com/ofds_layers.txt"
            }
          }
          EOF
          
          aws s3 cp pmtiles_metadata.json s3://${{ secrets.S3_BUCKET_NAME }}/pmtiles_metadata.json --content-type 'application/json' --cache-control 'max-age=300'